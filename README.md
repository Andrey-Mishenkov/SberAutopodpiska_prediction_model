## Проект: Предсказание целевых действий пользователей на сайте SberAutoPodpiska

**Разработка ML-модели для прогнозирования конверсии пользователей с последующим развертыванием в продакшен**

---

## Описание проекта

### Цель проекта
- Провести анализ поведения пользователей сайта «СберАвтоподписка» на основе данных о сессиях и событиях.
- Разработать модель машинного обучения для предсказания факта совершения целевого действия (подача заявки, звонок, заполнение формы и т.п.) в рамках сессии.
- Выбрать наиболее эффективную модель по метрике **ROC-AUC**, учитывая время обучения и стабильность.
- Подготовить модель к промышленной эксплуатации: упаковать в **REST API** (FastAPI), обеспечить время ответа < 3 секунд.
- Создать скрипты для периодического переобучения и тестирования модели на новых данных.

### Данные
Исходные данные состоят из двух таблиц, которые можно скачать по [ссылке](https://drive.google.com/drive/folders/1rA4o6KHH-M2KMvBLHp5DZ5gioF2q7hZw):

1. **ga_sessions** (1 860 042 сессии, 18 признаков):
   - `session_id`, `client_id`, `visit_date`, `visit_time`, `visit_number`
   - utm-метки: `utm_source`, `utm_medium`, `utm_campaign`, `utm_adcontent`, `utm_keyword`
   - информация об устройстве: `device_category`, `device_os`, `device_brand`, `device_model`, `device_screen_resolution`, `device_browser`
   - геоданные: `geo_country`, `geo_city`

2. **ga_hits** (15 726 470 событий, 11 признаков):
   - `session_id`, `hit_date`, `hit_time`, `hit_number`, `hit_type`, `hit_referer`, `hit_page_path`
   - `event_category`, `event_action`, `event_label`, `event_value`

Целевое действие определялось по списку `event_action`:
- `sub_car_claim_click`
- `sub_car_claim_submit_click`
- `sub_open_dialog_click`
- `sub_custom_question_submit_click`
- `sub_call_number_click`
- `sub_callback_submit_click`
- `sub_submit_success`
- `sub_car_request_submit_click`

---

## Этапы работы

### Часть 1. Подготовка данных и разведочный анализ (`part_1_data_preprocessing_and_analysis.ipynb`)

#### 1.1. Загрузка и первичная обработка
- Загрузка `ga_sessions.pkl` и `ga_hits.pkl` (время загрузки ~1.5 мин).
- Из `ga_hits` оставлены только `session_id` и `event_action`, создан бинарный признак `target_event_action` (1 – есть хотя бы одно целевое событие в сессии, 0 – иначе).
- Группировка по `session_id` с агрегацией `max(target_event_action)` – получено 1 734 610 уникальных сессий с целевой переменной.
- Соединение с `ga_sessions` (left join) – итоговый датасет `df_sessions` размером 1 860 042 × 19.
- Доля целевых сессий – **2.7%** (50 314 из 1 860 042), сильный дисбаланс классов.

#### 1.2. Очистка и заполнение пропусков
- Удален столбец `device_model` (99% пропусков).
- Пропуски в `utm_keyword`, `utm_adcontent`, `utm_campaign` заменены на `'other'`.
- `device_brand`: пустые значения и `'(not set)'` заменены на `'other'`.
- `device_os`: пропуски сначала заполнены `'(not set)'`, затем для каждого `device_brand` подставлена самая частая ОС (кроме `'(not set)'`), оставшиеся – модой.
- `geo_country` и `geo_city`: значения `'(not set)'` заменены на самые популярные для соответствующей страны.
- После обработки пропусков датасет стал полностью заполненным.

#### 1.3. Создание новых признаков (Feature Engineering)
На основе исходных данных сгенерированы:
- **Временные признаки**:
  - `visit_day_of_month`, `visit_day_of_week`, `visit_hour`
  - `visit_time_of_day` (категории: late_night, early_morning, morning, afternoon, evening, night)
  - `visit_is_peak_hour` (часы пик конверсии: 11–16)
  - `visit_days_since_first_visit` (сколько дней прошло с первого визита клиента)
- **Признаки устройства**:
  - `device_screen_width`, `device_screen_height` (из разрешения экрана, с округлением до сотен)
  - `device_screen_aspect_ratio` (отношение ширины к высоте, с ограничениями 0.5–3)
- **Географические признаки**:
  - `geo_latitude`, `geo_longitude` (получены через геокодер **geopy**, сохранены в `locations.csv` для ускорения)
  - `geo_distance_to_city_km` (расстояние от города до Москвы)
- **Признаки трафика**:
  - `utm_is_organic_traffic` (органические источники: '(none)', 'organic', 'referral')
  - `utm_is_advertising_in_social_networks` (источники рекламы в соцсетях)

#### 1.4. Анализ распределений и корреляций
- **Временная динамика**:
  - Рост посещаемости с мая по декабрь 2021 (с 100 150 тыс. до 400 тыс. сессий в месяц).
  - Конверсия при этом снизилась с 4–5% до 2%.
  - Наибольшая конверсия в начале недели (пн–ср), наименьшая – в выходные.
- **Устройства**:
  - Мобильные устройства составляют 70% трафика, десктопы – 25%, планшеты – 5%.
  - Конверсия на десктопах выше (3.5% против 2.5% на мобильных).
- **География**:
  - 99% сессий из России, топ-города: Москва, Санкт-Петербург, Новосибирск.
  - Конверсия выше в городах-миллионниках.
- **Корреляции**:
  - Наибольшая связь с целевой переменной у `visit_number` (порядковый номер визита) и `visit_days_since_first_visit` – чем дольше пользователь с сайтом, тем выше вероятность конверсии.
  - Также важны разрешение экрана и источники трафика.

#### 1.5. Преобразование категориальных признаков
- **High‑cardinality** (>100 уникальных значений): `utm_keyword`, `utm_campaign`, `utm_source`, `utm_adcontent`, `device_brand` – закодированы через **TargetEncoder**.
- **Medium‑cardinality** (10–100): `device_browser`, `utm_medium` – преобразованы **частотным кодированием** (frequency encoding).
- **Low‑cardinality** (<20): `device_os`, `device_category`, `visit_time_of_day` – обработаны **OneHotEncoder**.

#### 1.6. Масштабирование числовых признаков
- Числовые признаки (`visit_number`, временные, размеры экрана, геокоординаты, расстояние) стандартизированы с помощью **StandardScaler**.

#### 1.7. Матрицы корреляции
- Построены тепловые карты для групп признаков (visit, utm, device, geo) и для всех признаков вместе.
- Выявлены мультиколлинеарные пары (например, `device_category_mobile` и `device_category_desktop`), но решено оставить все признаки, так как модели сами справляются с отбором.

---

### Часть 2. Моделирование (`part_2_model_selection.ipynb`)

#### 2.1. Подготовка выборок
- Из-за сильного дисбаланса применен **undersampling**: для класса 0 оставлено в 2 раза больше записей, чем для класса 1. Итоговый размер: 150 942 строки (100 628 класса 0 + 50 314 класса 1).
- Разделение на train/test: 80/20 (`x_train`: 120 753, `x_test`: 30 189).

#### 2.2. Создание пайплайна предобработки
Разработан сложный пайплайн на основе `sklearn.pipeline.Pipeline` и `ColumnTransformer`, включающий все этапы обработки, описанные в части 1. Это обеспечивает воспроизводимость и готовность к продакшену.

#### 2.3. Сравнение моделей
Испытаны следующие алгоритмы (все с учетом дисбаланса через `class_weight` или `scale_pos_weight`):
- LogisticRegression
- RandomForestClassifier
- MLPClassifier
- XGBoost
- LightGBM
- CatBoost

**Результаты (на тестовой выборке после undersampling):**

| Модель               | ROC-AUC | Precision | Recall | F1-score | Время обучения, с |
|----------------------|---------|-----------|--------|----------|-------------------|
| XGBoost              | 0.7057  | 0.3554    | 0.9882 | 0.5228   | 0.80              |
| LightGBM             | 0.7051  | 0.3489    | 0.9970 | 0.5169   | 2.30              |
| CatBoost             | 0.7047  | 0.3534    | 0.9942 | 0.5214   | 24.85             |
| RandomForest         | 0.7024  | 0.4477    | 0.7417 | 0.5583   | 2.00              |
| LogisticRegression   | 0.6710  | 0.4370    | 0.6958 | 0.5369   | 2.58              |
| MLPClassifier        | 0.6676  | 0.5911    | 0.1575 | 0.2487   | 41.34             |

- **XGBoost** показал наилучший ROC-AUC, но **LightGBM** близок по качеству и значительно быстрее CatBoost.
- По совокупности (скорость + качество) лучшей выбрана **LightGBM**.

#### 2.4. Анализ важности признаков (LightGBM)
- **Группы признаков** (суммарная важность):
  - utm: 39.33%
  - visit: 28.40%
  - device: 19.33%
  - geo: 12.93%
- **Топ-10 признаков** (важность > 4%):
  - `utm_campaign` (10.43%)
  - `utm_source` (9.60%)
  - `utm_adcontent` (8.60%)
  - `visit_day_of_month` (6.77%)
  - `visit_number` (6.67%)
  - `utm_keyword` (6.40%)
  - `visit_hour` (5.30%)
  - `geo_longitude` (4.87%)
  - `geo_latitude` (4.50%)
  - `device_screen_height` (4.57%)
  - `device_browser_freq` (4.43%)

#### 2.5. Подбор гиперпараметров (LightGBM)
- Использован `GridSearchCV` с 3 фолдами по сетке:
  - `n_estimators`: [100, 200, 300]
  - `num_leaves`: [31, 50, 100]
  - `learning_rate`: [0.01, 0.1, 0.2]
  - `feature_fraction`: [0.8, 0.9, 1.0]
- Лучшие параметры:
  - `feature_fraction`: 0.9
  - `learning_rate`: 0.1
  - `n_estimators`: 100
  - `num_leaves`: 50
- Лучший ROC-AUC на кросс-валидации: **0.6979**.

#### 2.6. Финальная модель
- Обучили лучшую модель **LightGBM** на всем датасете (без undersampling, с учетом дисбаланса через `scale_pos_weight=37`).
- Итоговые метрики на всей выборке:
  - ROC-AUC: **0.7274**
  - Точность (precision) для класса 1: 0.0464 (из-за сильного дисбаланса)
  - Полнота (recall): 0.7416
  - F1: 0.0873
  - Accuracy: 0.5808

---

### Часть 3. Подготовка к продакшену

#### 3.1. Сохранение модели
- Модель (вместе с пайплайном) сохранена с помощью `dill` в файл `models/model_prediction_sber.pkl`.
- В файл также записаны метаданные: дата создания, тип модели, ROC-AUC и др.

#### 3.2. Тестирование на отдельных примерах (`testing_on_examples.py`)
- Создано 100 json-файлов (50 с target=1, 50 с target=0) из исходного датасета (функция `save_sessions_to_json` в ноутбуке).
- Скрипт загружает модель, последовательно обрабатывает файлы и сохраняет результаты в текстовый файл с временной меткой.
- Время обработки 100 файлов ~30 секунд.

#### 3.3. REST API на FastAPI (`main_api_sber.py`)
- Реализованы endpoints:
  - `GET /status` – проверка работоспособности.
  - `GET /version` – информация о модели (метаданные).
  - `POST /predict` – принимает JSON с параметрами сессии, возвращает предсказание (0/1) и фактическое значение target (если есть).
- Модель загружается при старте приложения.
- Входные данные валидируются через Pydantic-схему `SessionInfo`.
- Настроено логирование.

**Пример запроса:**
```json
{
  "session_id": "9055434745589932991.1637753792.1637753792",
  "client_id": "2108382700.1637753791",
  "visit_date": "2021-11-24",
  "visit_time": "14:36:32",
  "visit_number": 1,
  "utm_source": "ZpYIoDJMcFzVoPFsHGJL",
  "utm_medium": "banner",
  ...
}
```

**Пример ответа:**
```json
{
  "session_id": "9055434745589932991.1637753792.1637753792",
  "pred": 0,
  "target_action": 0
}
```

### 3.4. Скрипт для автоматического переобучения (`pipeline_model_sber.py`)
- Содержит все этапы предобработки, функции загрузки данных, создания пайплайна, кросс‑валидации, выбора лучшей модели и сохранения.
- Может быть использован для периодического переобучения модели при поступлении новых данных.
- В текущей версии в `main()` выполняется:
  - загрузка данных,
  - undersampling (коэффициент 2),
  - сравнение моделей (в отладочном режиме только LightGBM),
  - выбор лучшей,
  - обучение финальной модели на всех данных,
  - сохранение модели.

---

## Результаты и выводы

1. **Цель достигнута**
    - разработана модель, предсказывающая целевые действия пользователей с ROC‑AUC **0.7274** на всём датасете.
    - Несмотря на сильный дисбаланс, модель способна выделять около 74% потенциальных конверсий (recall), что приемлемо для задач приоритизации.

3. **Ключевые факторы успеха**:
   - Глубокая предобработка данных, включающая заполнение пропусков, генерацию новых признаков (геокоординаты, временные паттерны, разрешение экрана).
   - Использование undersampling для обучения на сбалансированных данных, что позволило корректно сравнивать модели.
   - Применение ансамблевых методов (LightGBM, XGBoost), которые лучше справляются с нелинейными зависимостями.
   - Тщательный подбор гиперпараметров с помощью GridSearchCV.

4. **Лучшая модель**
   - **LightGBM**, обеспечивающая хороший баланс качества и скорости.
   - После тюнинга она показала ROC‑AUC 0.7274 на полной выборке.

6. **Интерпретация**
   - важнейшие признаки оказались связаны с utm‑метками (источник, кампания, ключевое слово) и историей визитов (номер визита, день месяца, час).
   - Географические координаты также вносят заметный вклад, что подтверждает региональные различия в конверсии.

8. **Продакшен‑решение**:
   - Модель упакована в REST API (FastAPI) с временем ответа менее 1 секунды на типовой запрос.
   - Скрипты для тестирования и переобучения позволяют поддерживать модель в актуальном состоянии.
   - Всё решение готово к интеграции в бизнес‑процессы компании.

---

## Структура репозитория
```
Файлы ipynb:
    - part_1_data_preprocessing_and_analysis.ipynb – Jupyter Notebook с анализом данных и инженерией признаков.
    - part_2_model_selection.ipynb                 – Notebook с обучением, сравнением моделей, тюнингом и анализом важности.

Файлы py:
    - pipeline_model_sber.py                       – скрипт для полного цикла обучения и сохранения модели.
    - main_api_sber.py                             – FastAPI‑приложение для serving модели.
    - testing_on_examples.py                       – скрипт для тестирования модели на заранее подготовленных json‑файлах.

Директории:
    - data/          – директория с исходными данными (сами файлы из большого объема не включены в репозиторий).
    - models/        – директория для сохранённых моделей.
    - examples/      – примеры json‑запросов для тестирования.
    - test_results/  – результаты тестирования.

- README.md      – данный файл с описанием проекта.
  ```

Файлы с исходными данными можно скачать по [ссылке](https://drive.google.com/drive/folders/1rA4o6KHH-M2KMvBLHp5DZ5gioF2q7hZw)

---

## Заключение
- Проект успешно реализует полный цикл Data Science: от исследовательского анализа данных до развёртывания модели в виде микросервиса. 
- Полученная модель может быть использована для таргетирования пользователей с высокой вероятностью конверсии, оптимизации рекламных кампаний и улучшения пользовательского опыта.